{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sampled_data = pd.read_csv('added_sex_bias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_confusion_matrix(y_true, y_pred, group):\n",
    "    # Ensure that group is a boolean array for indexing\n",
    "    group = group.astype(bool)\n",
    "\n",
    "    # Filter the predictions and true values based on the group\n",
    "    y_true_group = y_true[group]\n",
    "    y_pred_group = y_pred[group]\n",
    "\n",
    "    # Calculate true positives, false positives, true negatives, and false negatives\n",
    "    tp = np.sum((y_pred_group == 1) & (y_true_group == 1))\n",
    "    tn = np.sum((y_pred_group == 0) & (y_true_group == 0))\n",
    "    fp = np.sum((y_pred_group == 1) & (y_true_group == 0))\n",
    "    fn = np.sum((y_pred_group == 0) & (y_true_group == 1))\n",
    "\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def EqualOpportunityDifference(y, pred, group_a, group_b):\n",
    "    tp_a, _, _, fn_a = calculate_confusion_matrix(y, pred, group_a)\n",
    "    tp_b, _, _, fn_b = calculate_confusion_matrix(y, pred, group_b)\n",
    "    tpr_a = tp_a / (tp_a + fn_a) if (tp_a + fn_a) > 0 else 0\n",
    "    tpr_b = tp_b / (tp_b + fn_b) if (tp_b + fn_b) > 0 else 0\n",
    "    return tpr_b - tpr_a\n",
    "\n",
    "def FalsePositiveRateBalance(y, pred, group_a, group_b):\n",
    "    _, tn_a, fp_a, _ = calculate_confusion_matrix(y, pred, group_a)\n",
    "    _, tn_b, fp_b, _ = calculate_confusion_matrix(y, pred, group_b)\n",
    "    fpr_a = fp_a / (fp_a + tn_a) if (fp_a + tn_a) > 0 else 0\n",
    "    fpr_b = fp_b / (fp_b + tn_b) if (fp_b + tn_b) > 0 else 0\n",
    "    return fpr_b - fpr_a\n",
    "\n",
    "def EqualisedOdds(y, pred, group_a, group_b):\n",
    "    return (EqualOpportunityDifference(y, pred, group_a, group_b) +\n",
    "            FalsePositiveRateBalance(y, pred, group_a, group_b)) / 2\n",
    "\n",
    "def PredictiveParityDifference(y, pred, group_a, group_b):\n",
    "    tp_a, _, fp_a, _ = calculate_confusion_matrix(y, pred, group_a)\n",
    "    tp_b, _, fp_b, _ = calculate_confusion_matrix(y, pred, group_b)\n",
    "    precision_a = tp_a / (tp_a + fp_a) if (tp_a + fp_a) > 0 else 0\n",
    "    precision_b = tp_b / (tp_b + fp_b) if (tp_b + fp_b) > 0 else 0\n",
    "    return precision_b - precision_a\n",
    "\n",
    "def StatisticalParityDifference(y, pred, group_a, group_b):\n",
    "    positive_rate_a = pred[group_a].mean()\n",
    "    positive_rate_b = pred[group_b].mean()\n",
    "    return positive_rate_b - positive_rate_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_data['group_a'] = (sampled_data['derived_race'] == 'White').astype(int)\n",
    "sampled_data['group_b'] = (sampled_data['derived_race'] != 'White').astype(int)\n",
    "sampled_data['group_c'] = (sampled_data['derived_race'] != 'Black or African American').astype(int)\n",
    "sampled_data['group_d'] = (sampled_data['derived_race'] == 'Black or African American').astype(int)\n",
    "sampled_data['group_e'] = (sampled_data['derived_sex'] == 'Male').astype(int)\n",
    "sampled_data['group_f'] = (sampled_data['derived_sex'] == 'Female').astype(int)\n",
    "sampled_data['group_g'] = (sampled_data['derived_race'] == 'Asian').astype(int)\n",
    "sampled_data['group_h'] = (sampled_data['derived_race'] == 'Black').astype(int)\n",
    "sampled_data['group_i'] = (sampled_data['derived_race'] == 'White').astype(int)\n",
    "sampled_data['group_j'] = (sampled_data['derived_race'] == 'Asian').astype(int)\n",
    "\n",
    "group_a = sampled_data['group_a'].copy() \n",
    "group_b = sampled_data['group_b'].copy()\n",
    "group_c = sampled_data['group_c'].copy() \n",
    "group_d = sampled_data['group_d'].copy()\n",
    "group_e = sampled_data['group_e'].copy() \n",
    "group_f = sampled_data['group_f'].copy()\n",
    "group_g = sampled_data['group_g'].copy() \n",
    "group_h = sampled_data['group_h'].copy()\n",
    "group_i = sampled_data['group_i'].copy() \n",
    "group_j = sampled_data['group_j'].copy()\n",
    "\n",
    "bias_metrics = {\n",
    "    \"Equal Opportunity Difference\": EqualOpportunityDifference,\n",
    "    \"False Positive Rate Balance\": FalsePositiveRateBalance,\n",
    "    \"Equalised Odds\": EqualisedOdds,\n",
    "    \"Predictive Parity Difference\": PredictiveParityDifference,\n",
    "    \"Statistical Parity Difference\": StatisticalParityDifference\n",
    "}\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score, roc_auc_score\n",
    "\n",
    "# setup the metrics to be computed\n",
    "from sklearn import metrics\n",
    "perf_metrics = {\"Accuracy\": metrics.accuracy_score, \n",
    "                \"Precision\": metrics.precision_score, \n",
    "                \"Recall\": metrics.recall_score,\n",
    "                \"AUC\": metrics.roc_auc_score, \n",
    "                \"F1-Score\": metrics.f1_score,\n",
    "                }\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming sampled_data is your DataFrame\n",
    "y = sampled_data['action_taken']\n",
    "\n",
    "# Exclude both 'action_taken' and 'applicant_race_1' from the features\n",
    "X = sampled_data.drop(['Unnamed: 0','action_taken', 'derived_race','derived_sex'], axis=1)\n",
    "\n",
    "test_set = 0.2\n",
    "seed = 123\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_set, random_state=seed, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/visharlya/.virtualenvs/py3cv4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/visharlya/.virtualenvs/py3cv4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/visharlya/.virtualenvs/py3cv4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/visharlya/.virtualenvs/py3cv4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/visharlya/.virtualenvs/py3cv4/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "\n",
    "lr = LogisticRegression(random_state=10, solver=\"lbfgs\", penalty=\"none\", max_iter=1000)\n",
    "mv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "white_metrics_all = pd.DataFrame()\n",
    "black_metrics_all = pd.DataFrame()\n",
    "sex_metrics_all = pd.DataFrame()\n",
    "asianblack_metrics_all = pd.DataFrame()\n",
    "asianwhite_metrics_all = pd.DataFrame()\n",
    "k, i = True, 1\n",
    "i = 1\n",
    "for (train, test) in mv.split(X, y):\n",
    "    lr.fit(X.iloc[train], y.iloc[train].values.ravel())\n",
    "    ypred_prob = lr.predict_proba(X.iloc[test]).ravel()[1::2] # get probabilities\n",
    "    ypred_class = lr.predict(X.iloc[test])\n",
    "\n",
    "    # compute performance metrics\n",
    "    metrics = []\n",
    "    for pf in perf_metrics.keys():\n",
    "        if pf in [\"AUC\", \"Brier\"]:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_prob)]]\n",
    "        else:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_class)]]\n",
    "\n",
    "    # concatenate results\n",
    "    df_m = pd.DataFrame(metrics, columns=[\"Metric\", \"Value\"])\n",
    "    df_m[\"Fold\"] = i\n",
    "    i += 1\n",
    "    if k:\n",
    "        df_metrics = df_m.copy()\n",
    "        k=0\n",
    "    else:\n",
    "        df_metrics = pd.concat([df_metrics, df_m.copy()], axis=0, ignore_index=True)\n",
    "\n",
    "    # Reset these lists inside the loop for each fold\n",
    "    white_metrics = []\n",
    "    black_metrics = []\n",
    "    sex_metrics = []\n",
    "    asianblack_metrics = []\n",
    "    asianwhite_metrics = []\n",
    "\n",
    "    for bias in bias_metrics.keys():\n",
    "        white_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_a[test], group_b[test])])\n",
    "        black_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_c[test], group_d[test])])                                    \n",
    "        sex_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_e[test], group_f[test])])\n",
    "        asianblack_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_g[test], group_h[test])])\n",
    "        asianwhite_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_i[test], group_j[test])])\n",
    "\n",
    "        # Convert lists to DataFrames before concatenation\n",
    "        white_df = pd.DataFrame(white_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        black_df = pd.DataFrame(black_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        sex_df = pd.DataFrame(sex_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianwhite_df = pd.DataFrame(asianwhite_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianblack_df = pd.DataFrame(asianblack_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        \n",
    "\n",
    "    # Concatenate the new DataFrames with the all metrics DataFrames\n",
    "    white_metrics_all = pd.concat([white_metrics_all, white_df], axis=0)\n",
    "    black_metrics_all = pd.concat([black_metrics_all, black_df], axis=0)\n",
    "    sex_metrics_all = pd.concat([sex_metrics_all, sex_df], axis=0)\n",
    "    asianblack_metrics_all = pd.concat([asianblack_metrics_all, asianblack_df], axis=0)\n",
    "    asianwhite_metrics_all = pd.concat([asianwhite_metrics_all, asianwhite_df], axis=0)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "white_summary = white_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "black_summary = black_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "sex_summary = sex_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianblack_summary = asianblack_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianwhite_summary = asianwhite_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.984604</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.951635</td>\n",
       "      <td>0.000738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.971444</td>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.982941</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.960217</td>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean       std\n",
       "              Value     Value\n",
       "Metric                       \n",
       "AUC        0.984604  0.000522\n",
       "Accuracy   0.951635  0.000738\n",
       "F1-Score   0.971444  0.000475\n",
       "Precision  0.982941  0.001102\n",
       "Recall     0.960217  0.001894"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If 'Value' is not a numeric type, you may need to convert it\n",
    "if not pd.api.types.is_numeric_dtype(df_metrics['Value']):\n",
    "    df_metrics['Value'] = pd.to_numeric(df_metrics['Value'], errors='coerce')\n",
    "\n",
    "# Now try creating the pivot table again\n",
    "pivot_table = df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
    "df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.boxplot(column='Value', by='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHITE/NOT WHITE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>-0.004201</td>\n",
       "      <td>0.001708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>0.025488</td>\n",
       "      <td>0.010231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>0.055177</td>\n",
       "      <td>0.021563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>-0.017592</td>\n",
       "      <td>0.004013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.129906</td>\n",
       "      <td>0.290480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference  -0.004201  0.001708\n",
       "Equalised Odds                 0.025488  0.010231\n",
       "False Positive Rate Balance    0.055177  0.021563\n",
       "Predictive Parity Difference  -0.017592  0.004013\n",
       "Statistical Parity Difference  0.129906  0.290480"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"WHITE/NOT WHITE:\")\n",
    "white_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLACK/NOT BLACK:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>-0.021904</td>\n",
       "      <td>0.004508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>-0.059337</td>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>-0.096769</td>\n",
       "      <td>0.008748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>0.012413</td>\n",
       "      <td>0.002079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.168685</td>\n",
       "      <td>0.377190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference  -0.021904  0.004508\n",
       "Equalised Odds                -0.059337  0.003517\n",
       "False Positive Rate Balance   -0.096769  0.008748\n",
       "Predictive Parity Difference   0.012413  0.002079\n",
       "Statistical Parity Difference  0.168685  0.377190"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nBLACK/NOT BLACK:\")\n",
    "black_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MALE/FEMALE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.001852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>-0.011654</td>\n",
       "      <td>0.005981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>-0.025949</td>\n",
       "      <td>0.011082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.031263</td>\n",
       "      <td>0.069906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference   0.002640  0.001852\n",
       "Equalised Odds                -0.011654  0.005981\n",
       "False Positive Rate Balance   -0.025949  0.011082\n",
       "Predictive Parity Difference   0.004097  0.002337\n",
       "Statistical Parity Difference  0.031263  0.069906"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nMALE/FEMALE:\")\n",
    "sex_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASIAN/WHITE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.008520</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>0.155050</td>\n",
       "      <td>0.024389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>0.301580</td>\n",
       "      <td>0.048213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>-0.037310</td>\n",
       "      <td>0.006416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.147573</td>\n",
       "      <td>0.329984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference   0.008520  0.000932\n",
       "Equalised Odds                 0.155050  0.024389\n",
       "False Positive Rate Balance    0.301580  0.048213\n",
       "Predictive Parity Difference  -0.037310  0.006416\n",
       "Statistical Parity Difference  0.147573  0.329984"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nASIAN/WHITE:\")\n",
    "asianwhite_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ASIAN/BLACK:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>-0.969442</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>-0.679288</td>\n",
       "      <td>0.020921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>-0.389134</td>\n",
       "      <td>0.041498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>-0.948622</td>\n",
       "      <td>0.005280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.038863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference  -0.969442  0.001513\n",
       "Equalised Odds                -0.679288  0.020921\n",
       "False Positive Rate Balance   -0.389134  0.041498\n",
       "Predictive Parity Difference  -0.948622  0.005280\n",
       "Statistical Parity Difference  0.017380  0.038863"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\ASIAN/BLACK:\")\n",
    "asianblack_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.LinearExplainer(lr, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# Initialize the XGBClassifier\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "mv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "import pandas as pd\n",
    "k, i = True, 1\n",
    "\n",
    "for (train, test) in mv.split(X, y):\n",
    "    # fit model\n",
    "    xgb_clf = xgb_clf.fit(X.iloc[train], y.iloc[train].values.ravel())\n",
    "    \n",
    "    # get predictions in the test set\n",
    "    ypred_prob = xgb_clf.predict_proba(X.iloc[test]).ravel()[1::2] # get probabilities\n",
    "    ypred_class = xgb_clf.predict(X.iloc[test])\n",
    "    # compute performance metrics\n",
    "    metrics = []\n",
    "    for pf in perf_metrics.keys():\n",
    "        if pf in [\"AUC\", \"Brier\"]:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_prob)]]\n",
    "        else:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_class)]]\n",
    "\n",
    "    # concatenate results\n",
    "    df_m = pd.DataFrame(metrics, columns=[\"Metric\", \"Value\"])\n",
    "    df_m[\"Fold\"] = i\n",
    "    i += 1\n",
    "    if k:\n",
    "        df_metrics = df_m.copy()\n",
    "        k=0\n",
    "    else:\n",
    "        df_metrics = pd.concat([df_metrics, df_m.copy()], axis=0, ignore_index=True)\n",
    "\n",
    "    # compute performance metrics\n",
    "    white_metrics = []\n",
    "    black_metrics = []\n",
    "    sex_metrics = []\n",
    "    for bias in bias_metrics.keys():\n",
    "        white_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_a[test], group_b[test])])\n",
    "        black_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_c[test], group_d[test])])                                    \n",
    "        sex_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_e[test], group_f[test])])\n",
    "        asianblack_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_g[test], group_h[test])])\n",
    "        asianwhite_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_i[test], group_j[test])])\n",
    "\n",
    "        # Convert lists to DataFrames before concatenation\n",
    "        white_df = pd.DataFrame(white_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        black_df = pd.DataFrame(black_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        sex_df = pd.DataFrame(sex_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianwhite_df = pd.DataFrame(asianwhite_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianblack_df = pd.DataFrame(asianblack_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        \n",
    "\n",
    "    # Concatenate the new DataFrames with the all metrics DataFrames\n",
    "    white_metrics_all = pd.concat([white_metrics_all, white_df], axis=0)\n",
    "    black_metrics_all = pd.concat([black_metrics_all, black_df], axis=0)\n",
    "    sex_metrics_all = pd.concat([sex_metrics_all, sex_df], axis=0)\n",
    "    asianblack_metrics_all = pd.concat([asianblack_metrics_all, asianblack_df], axis=0)\n",
    "    asianwhite_metrics_all = pd.concat([asianwhite_metrics_all, asianwhite_df], axis=0)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "white_summary = white_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "black_summary = black_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "sex_summary = sex_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianblack_summary = asianblack_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianwhite_summary = asianwhite_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'Value' is not a numeric type, you may need to convert it\n",
    "if not pd.api.types.is_numeric_dtype(df_metrics['Value']):\n",
    "    df_metrics['Value'] = pd.to_numeric(df_metrics['Value'], errors='coerce')\n",
    "\n",
    "# Now try creating the pivot table again\n",
    "pivot_table = df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
    "df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.boxplot(column='Value', by='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WHITE/NOT WHITE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>-0.001523</td>\n",
       "      <td>0.003754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>0.015755</td>\n",
       "      <td>0.012902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>0.033034</td>\n",
       "      <td>0.028244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>-0.013065</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.129906</td>\n",
       "      <td>0.273867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference  -0.001523  0.003754\n",
       "Equalised Odds                 0.015755  0.012902\n",
       "False Positive Rate Balance    0.033034  0.028244\n",
       "Predictive Parity Difference  -0.013065  0.005638\n",
       "Statistical Parity Difference  0.129906  0.273867"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"WHITE/NOT WHITE:\")\n",
    "white_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BLACK/NOT BLACK:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>-0.021651</td>\n",
       "      <td>0.004320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>-0.052048</td>\n",
       "      <td>0.009157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>-0.082444</td>\n",
       "      <td>0.018537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.005758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.168685</td>\n",
       "      <td>0.355619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference  -0.021651  0.004320\n",
       "Equalised Odds                -0.052048  0.009157\n",
       "False Positive Rate Balance   -0.082444  0.018537\n",
       "Predictive Parity Difference   0.007608  0.005758\n",
       "Statistical Parity Difference  0.168685  0.355619"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nBLACK/NOT BLACK:\")\n",
    "black_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MALE/FEMALE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.001623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>-0.011883</td>\n",
       "      <td>0.006916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>-0.026274</td>\n",
       "      <td>0.012728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.031263</td>\n",
       "      <td>0.065908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference   0.002508  0.001623\n",
       "Equalised Odds                -0.011883  0.006916\n",
       "False Positive Rate Balance   -0.026274  0.012728\n",
       "Predictive Parity Difference   0.004120  0.002642\n",
       "Statistical Parity Difference  0.031263  0.065908"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nMALE/FEMALE:\")\n",
    "sex_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASIAN/WHITE:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.005265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>0.116182</td>\n",
       "      <td>0.043858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>0.218343</td>\n",
       "      <td>0.091746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>-0.026775</td>\n",
       "      <td>0.013399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.118059</td>\n",
       "      <td>0.276085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference   0.014022  0.005265\n",
       "Equalised Odds                 0.116182  0.043858\n",
       "False Positive Rate Balance    0.218343  0.091746\n",
       "Predictive Parity Difference  -0.026775  0.013399\n",
       "Statistical Parity Difference  0.118059  0.276085"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nASIAN/WHITE:\")\n",
    "asianwhite_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ASIAN/BLACK:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Equal Opportunity Difference</th>\n",
       "      <td>-0.980034</td>\n",
       "      <td>0.009663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Equalised Odds</th>\n",
       "      <td>-0.644589</td>\n",
       "      <td>0.035926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive Rate Balance</th>\n",
       "      <td>-0.309143</td>\n",
       "      <td>0.080852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predictive Parity Difference</th>\n",
       "      <td>-0.958727</td>\n",
       "      <td>0.011735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistical Parity Difference</th>\n",
       "      <td>0.013904</td>\n",
       "      <td>0.032515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean       std\n",
       "                                  Value     Value\n",
       "Metric                                           \n",
       "Equal Opportunity Difference  -0.980034  0.009663\n",
       "Equalised Odds                -0.644589  0.035926\n",
       "False Positive Rate Balance   -0.309143  0.080852\n",
       "Predictive Parity Difference  -0.958727  0.011735\n",
       "Statistical Parity Difference  0.013904  0.032515"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\ASIAN/BLACK:\")\n",
    "asianblack_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.LinearExplainer(xgb_clf, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "mv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "import pandas as pd\n",
    "k, i = True, 1\n",
    "\n",
    "for (train, test) in mv.split(X, y):\n",
    "    # fit model\n",
    "    random_forest = random_forest.fit(X.iloc[train], y.iloc[train].values.ravel())\n",
    "    \n",
    "    # get predictions in the test set\n",
    "    ypred_prob = random_forest.predict_proba(X.iloc[test]).ravel()[1::2] # get probabilities\n",
    "    ypred_class = random_forest.predict(X.iloc[test])\n",
    "    # compute performance metrics\n",
    "    metrics = []\n",
    "    for pf in perf_metrics.keys():\n",
    "        if pf in [\"AUC\", \"Brier\"]:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_prob)]]\n",
    "        else:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_class)]]\n",
    "\n",
    "    # concatenate results\n",
    "    df_m = pd.DataFrame(metrics, columns=[\"Metric\", \"Value\"])\n",
    "    df_m[\"Fold\"] = i\n",
    "    i += 1\n",
    "    if k:\n",
    "        df_metrics = df_m.copy()\n",
    "        k=0\n",
    "    else:\n",
    "        df_metrics = pd.concat([df_metrics, df_m.copy()], axis=0, ignore_index=True)\n",
    "\n",
    "    # compute performance metrics\n",
    "    white_metrics = []\n",
    "    black_metrics = []\n",
    "    sex_metrics = []\n",
    "    for bias in bias_metrics.keys():\n",
    "        white_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_a[test], group_b[test])])\n",
    "        black_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_c[test], group_d[test])])                                    \n",
    "        sex_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_e[test], group_f[test])])\n",
    "        asianblack_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_g[test], group_h[test])])\n",
    "        asianwhite_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_i[test], group_j[test])])\n",
    "\n",
    "        # Convert lists to DataFrames before concatenation\n",
    "        white_df = pd.DataFrame(white_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        black_df = pd.DataFrame(black_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        sex_df = pd.DataFrame(sex_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianwhite_df = pd.DataFrame(asianwhite_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianblack_df = pd.DataFrame(asianblack_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        \n",
    "\n",
    "    # Concatenate the new DataFrames with the all metrics DataFrames\n",
    "    white_metrics_all = pd.concat([white_metrics_all, white_df], axis=0)\n",
    "    black_metrics_all = pd.concat([black_metrics_all, black_df], axis=0)\n",
    "    sex_metrics_all = pd.concat([sex_metrics_all, sex_df], axis=0)\n",
    "    asianblack_metrics_all = pd.concat([asianblack_metrics_all, asianblack_df], axis=0)\n",
    "    asianwhite_metrics_all = pd.concat([asianwhite_metrics_all, asianwhite_df], axis=0)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "white_summary = white_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "black_summary = black_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "sex_summary = sex_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianblack_summary = asianblack_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianwhite_summary = asianwhite_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'Value' is not a numeric type, you may need to convert it\n",
    "if not pd.api.types.is_numeric_dtype(df_metrics['Value']):\n",
    "    df_metrics['Value'] = pd.to_numeric(df_metrics['Value'], errors='coerce')\n",
    "\n",
    "# Now try creating the pivot table again\n",
    "pivot_table = df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
    "df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.boxplot(column='Value', by='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WHITE/NOT WHITE:\")\n",
    "white_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBLACK/NOT BLACK:\")\n",
    "black_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMALE/FEMALE:\")\n",
    "sex_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nASIAN/WHITE:\")\n",
    "asianwhite_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ASIAN/BLACK:\")\n",
    "asianblack_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.LinearExplainer(random_forest, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # Create an SVM classifier\n",
    "# svm = SVC(random_state=42)\n",
    "\n",
    "# mv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "import pandas as pd\n",
    "k, i = True, 1\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svm = svm.SVC(random_state=10, probability=True)\n",
    "\n",
    "for (train, test) in mv.split(X, y):\n",
    "    svm = svm.fit(X.iloc[train], y.iloc[train].values.ravel())\n",
    "    \n",
    "    ypred_prob = svm.predict_proba(X.iloc[test]).ravel()[1::2] # get probabilities\n",
    "    ypred_class = svm.predict(X.iloc[test])\n",
    "    # compute performance metrics\n",
    "    metrics = []\n",
    "    for pf in perf_metrics.keys():\n",
    "        if pf in [\"AUC\", \"Brier\"]:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_prob)]]\n",
    "        else:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_class)]]\n",
    "\n",
    "    # concatenate results\n",
    "    df_m = pd.DataFrame(metrics, columns=[\"Metric\", \"Value\"])\n",
    "    df_m[\"Fold\"] = i\n",
    "    i += 1\n",
    "    if k:\n",
    "        df_metrics = df_m.copy()\n",
    "        k=0\n",
    "    else:\n",
    "        df_metrics = pd.concat([df_metrics, df_m.copy()], axis=0, ignore_index=True)\n",
    "\n",
    "    white_metrics = []\n",
    "    black_metrics = []\n",
    "    sex_metrics = []\n",
    "    for bias in bias_metrics.keys():\n",
    "        white_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_a[test], group_b[test])])\n",
    "        black_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_c[test], group_d[test])])                                    \n",
    "        sex_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_e[test], group_f[test])])\n",
    "        asianblack_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_g[test], group_h[test])])\n",
    "        asianwhite_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_i[test], group_j[test])])\n",
    "\n",
    "        # Convert lists to DataFrames before concatenation\n",
    "        white_df = pd.DataFrame(white_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        black_df = pd.DataFrame(black_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        sex_df = pd.DataFrame(sex_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianwhite_df = pd.DataFrame(asianwhite_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianblack_df = pd.DataFrame(asianblack_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        \n",
    "\n",
    "    # Concatenate the new DataFrames with the all metrics DataFrames\n",
    "    white_metrics_all = pd.concat([white_metrics_all, white_df], axis=0)\n",
    "    black_metrics_all = pd.concat([black_metrics_all, black_df], axis=0)\n",
    "    sex_metrics_all = pd.concat([sex_metrics_all, sex_df], axis=0)\n",
    "    asianblack_metrics_all = pd.concat([asianblack_metrics_all, asianblack_df], axis=0)\n",
    "    asianwhite_metrics_all = pd.concat([asianwhite_metrics_all, asianwhite_df], axis=0)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "white_summary = white_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "black_summary = black_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "sex_summary = sex_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianblack_summary = asianblack_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianwhite_summary = asianwhite_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'Value' is not a numeric type, you may need to convert it\n",
    "if not pd.api.types.is_numeric_dtype(df_metrics['Value']):\n",
    "    df_metrics['Value'] = pd.to_numeric(df_metrics['Value'], errors='coerce')\n",
    "\n",
    "# Now try creating the pivot table again\n",
    "pivot_table = df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
    "df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.boxplot(column='Value', by='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WHITE/NOT WHITE:\")\n",
    "white_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBLACK/NOT BLACK:\")\n",
    "black_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMALE/FEMALE:\")\n",
    "sex_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nASIAN/WHITE:\")\n",
    "asianwhite_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ASIAN/BLACK:\")\n",
    "asianblack_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.LinearExplainer(svm, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "\n",
    "parameters = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "lgb_model = lgb.train(parameters,\n",
    "                  train_data,\n",
    "                  valid_sets=[valid_data],\n",
    "                  num_boost_round=5000)\n",
    "\n",
    "mv = StratifiedKFold(n_splits=5, shuffle=True, random_state=10)\n",
    "\n",
    "import pandas as pd\n",
    "k, i = True, 1\n",
    "\n",
    "for (train, test) in mv.split(X, y):\n",
    "    # fit model\n",
    "    lgb_model = lgb_model.fit(X.iloc[train], y.iloc[train].values.ravel())\n",
    "    \n",
    "    # get predictions in the test set\n",
    "    ypred_prob = lgb_model.predict_proba(X.iloc[test]).ravel()[1::2] # get probabilities\n",
    "    ypred_class = lgb_model.predict(X.iloc[test])\n",
    "    # compute performance metrics\n",
    "    metrics = []\n",
    "    for pf in perf_metrics.keys():\n",
    "        if pf in [\"AUC\", \"Brier\"]:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_prob)]]\n",
    "        else:\n",
    "            metrics += [[pf, perf_metrics[pf](y.iloc[test].values.ravel(), ypred_class)]]\n",
    "\n",
    "    # concatenate results\n",
    "    df_m = pd.DataFrame(metrics, columns=[\"Metric\", \"Value\"])\n",
    "    df_m[\"Fold\"] = i\n",
    "    i += 1\n",
    "    if k:\n",
    "        df_metrics = df_m.copy()\n",
    "        k=0\n",
    "    else:\n",
    "        df_metrics = pd.concat([df_metrics, df_m.copy()], axis=0, ignore_index=True)\n",
    "\n",
    "    # compute performance metrics\n",
    "    white_metrics = []\n",
    "    black_metrics = []\n",
    "    sex_metrics = []\n",
    "    for bias in bias_metrics.keys():\n",
    "        white_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_a[test], group_b[test])])\n",
    "        black_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_c[test], group_d[test])])                                    \n",
    "        sex_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_e[test], group_f[test])])\n",
    "        asianblack_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_g[test], group_h[test])])\n",
    "        asianwhite_metrics.append([bias, bias_metrics[bias](y.iloc[test].values.ravel(), ypred_class,\n",
    "                                        group_i[test], group_j[test])])\n",
    "\n",
    "        # Convert lists to DataFrames before concatenation\n",
    "        white_df = pd.DataFrame(white_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        black_df = pd.DataFrame(black_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        sex_df = pd.DataFrame(sex_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianwhite_df = pd.DataFrame(asianwhite_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        asianblack_df = pd.DataFrame(asianblack_metrics, columns=[\"Metric\", \"Value\"]).assign(Fold=i)\n",
    "        \n",
    "\n",
    "    # Concatenate the new DataFrames with the all metrics DataFrames\n",
    "    white_metrics_all = pd.concat([white_metrics_all, white_df], axis=0)\n",
    "    black_metrics_all = pd.concat([black_metrics_all, black_df], axis=0)\n",
    "    sex_metrics_all = pd.concat([sex_metrics_all, sex_df], axis=0)\n",
    "    asianblack_metrics_all = pd.concat([asianblack_metrics_all, asianblack_df], axis=0)\n",
    "    asianwhite_metrics_all = pd.concat([asianwhite_metrics_all, asianwhite_df], axis=0)\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "white_summary = white_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "black_summary = black_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "sex_summary = sex_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianblack_summary = asianblack_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])\n",
    "asianwhite_summary = asianwhite_metrics_all.pivot_table(index='Metric', values='Value', aggfunc=['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'Value' is not a numeric type, you may need to convert it\n",
    "if not pd.api.types.is_numeric_dtype(df_metrics['Value']):\n",
    "    df_metrics['Value'] = pd.to_numeric(df_metrics['Value'], errors='coerce')\n",
    "\n",
    "# Now try creating the pivot table again\n",
    "pivot_table = df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n",
    "df_metrics.pivot_table(index=\"Metric\", values=\"Value\", aggfunc=[\"mean\", \"std\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.boxplot(column='Value', by='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WHITE/NOT WHITE:\")\n",
    "white_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBLACK/NOT BLACK:\")\n",
    "black_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMALE/FEMALE:\")\n",
    "sex_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nASIAN/WHITE:\")\n",
    "asianwhite_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\ASIAN/BLACK:\")\n",
    "asianblack_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explainer = shap.LinearExplainer(lgb_model, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab01467e1ba0f853da7a9f5b7c73c9bf62ddfc76943c22f8ed9be678f3a21eaa"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit ('py3cv4': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
